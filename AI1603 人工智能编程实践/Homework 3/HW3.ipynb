{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaf8ab0",
   "metadata": {},
   "source": [
    "### 模块初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a371e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8276c9d4",
   "metadata": {},
   "source": [
    "### 构建数据集读取器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c03d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTReader(datasets.VisionDataset):\n",
    "    def __init__(self, path) -> None:\n",
    "        self.data_label = torch.load(path)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return 20000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, target = self.data_label[index]\n",
    "        return self.transform(image), target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5f14c",
   "metadata": {},
   "source": [
    "### 构建分类神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f1e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 1024),\n",
    "            nn.Linear(1024, 10),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d171fc",
   "metadata": {},
   "source": [
    "### 载入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "486f617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset train1 loaded, size = 20000\n",
      "Dataset train2 loaded, size = 20000\n",
      "Dataset test loaded, size = 20000\n"
     ]
    }
   ],
   "source": [
    "# Dataset train1\n",
    "train1_dataset = MNISTReader('./ColoredMNIST/train1.pt')\n",
    "train1_loader = DataLoader(train1_dataset, batch_size=32)\n",
    "train1_size = len(train1_dataset)\n",
    "print(\"Dataset train1 loaded, size = {}\".format(train1_size))\n",
    "\n",
    "# Dataset train2\n",
    "train2_dataset = MNISTReader('./ColoredMNIST/train2.pt')\n",
    "train2_loader = DataLoader(train2_dataset, batch_size=32)\n",
    "train2_size = len(train2_dataset)\n",
    "print(\"Dataset train2 loaded, size = {}\".format(train2_size))\n",
    "\n",
    "# Dataset test\n",
    "test_dataset = MNISTReader('./ColoredMNIST/test.pt')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "test_size = len(test_dataset)\n",
    "print(\"Dataset test loaded, size = {}\".format(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e456c",
   "metadata": {},
   "source": [
    "### 在训练集 `train1.pt` 上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27517cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Training round 1 started ----------\n",
      "Training progress: 100, Loss: 0.42508256435394287\n",
      "Training progress: 200, Loss: 0.34051600098609924\n",
      "Training progress: 300, Loss: 0.6473428606987\n",
      "Training progress: 400, Loss: 0.5770722031593323\n",
      "Training progress: 500, Loss: 0.4550929367542267\n",
      "Training progress: 600, Loss: 0.4551681578159332\n",
      "Total loss: 731.3696899414062, Accuracy: 0.14309999346733093\n",
      "---------- Training round 1 finished ----------\n",
      "---------- Training round 2 started ----------\n",
      "Training progress: 700, Loss: 0.3683050870895386\n",
      "Training progress: 800, Loss: 0.7079054117202759\n",
      "Training progress: 900, Loss: 0.6171107888221741\n",
      "Training progress: 1000, Loss: 0.5512687563896179\n",
      "Training progress: 1100, Loss: 0.5211177468299866\n",
      "Training progress: 1200, Loss: 0.541061282157898\n",
      "Total loss: 727.6994018554688, Accuracy: 0.17520000040531158\n",
      "---------- Training round 2 finished ----------\n",
      "---------- Training round 3 started ----------\n",
      "Training progress: 1300, Loss: 0.5683028101921082\n",
      "Training progress: 1400, Loss: 0.5373333096504211\n",
      "Training progress: 1500, Loss: 0.49789857864379883\n",
      "Training progress: 1600, Loss: 0.4486684203147888\n",
      "Training progress: 1700, Loss: 0.5741875171661377\n",
      "Training progress: 1800, Loss: 0.30988216400146484\n",
      "Total loss: 744.5401000976562, Accuracy: 0.19325000047683716\n",
      "---------- Training round 3 finished ----------\n",
      "---------- Training round 4 started ----------\n",
      "Training progress: 1900, Loss: 0.499435156583786\n",
      "Training progress: 2000, Loss: 0.39653894305229187\n",
      "Training progress: 2100, Loss: 0.48813071846961975\n",
      "Training progress: 2200, Loss: 0.44633281230926514\n",
      "Training progress: 2300, Loss: 0.342465877532959\n",
      "Training progress: 2400, Loss: 0.28983333706855774\n",
      "Training progress: 2500, Loss: 0.5157095789909363\n",
      "Total loss: 745.9987182617188, Accuracy: 0.18084999918937683\n",
      "---------- Training round 4 finished ----------\n",
      "---------- Training round 5 started ----------\n",
      "Training progress: 2600, Loss: 0.28965967893600464\n",
      "Training progress: 2700, Loss: 0.2860705554485321\n",
      "Training progress: 2800, Loss: 0.7587965130805969\n",
      "Training progress: 2900, Loss: 0.5085126161575317\n",
      "Training progress: 3000, Loss: 0.3994687497615814\n",
      "Training progress: 3100, Loss: 0.4238123893737793\n",
      "Total loss: 776.9541015625, Accuracy: 0.1910499930381775\n",
      "---------- Training round 5 finished ----------\n",
      "---------- Training round 6 started ----------\n",
      "Training progress: 3200, Loss: 0.3551100194454193\n",
      "Training progress: 3300, Loss: 0.5917028784751892\n",
      "Training progress: 3400, Loss: 0.5565493106842041\n",
      "Training progress: 3500, Loss: 0.4804413914680481\n",
      "Training progress: 3600, Loss: 0.5419905781745911\n",
      "Training progress: 3700, Loss: 0.5470830798149109\n",
      "Total loss: 798.5516967773438, Accuracy: 0.18230000138282776\n",
      "---------- Training round 6 finished ----------\n",
      "---------- Training round 7 started ----------\n",
      "Training progress: 3800, Loss: 0.5502526760101318\n",
      "Training progress: 3900, Loss: 0.5556079149246216\n",
      "Training progress: 4000, Loss: 0.4756149649620056\n",
      "Training progress: 4100, Loss: 0.41120782494544983\n",
      "Training progress: 4200, Loss: 0.5343129634857178\n",
      "Training progress: 4300, Loss: 0.2509814202785492\n",
      "Total loss: 766.1912231445312, Accuracy: 0.22964999079704285\n",
      "---------- Training round 7 finished ----------\n",
      "---------- Training round 8 started ----------\n",
      "Training progress: 4400, Loss: 0.5248899459838867\n",
      "Training progress: 4500, Loss: 0.41275396943092346\n",
      "Training progress: 4600, Loss: 0.5625648498535156\n",
      "Training progress: 4700, Loss: 0.46160346269607544\n",
      "Training progress: 4800, Loss: 0.31318768858909607\n",
      "Training progress: 4900, Loss: 0.2887763977050781\n",
      "Training progress: 5000, Loss: 0.47925445437431335\n",
      "Total loss: 767.3843994140625, Accuracy: 0.28360000252723694\n",
      "---------- Training round 8 finished ----------\n",
      "---------- Training round 9 started ----------\n",
      "Training progress: 5100, Loss: 0.25113150477409363\n",
      "Training progress: 5200, Loss: 0.25220686197280884\n",
      "Training progress: 5300, Loss: 0.7401933073997498\n",
      "Training progress: 5400, Loss: 0.5128480195999146\n",
      "Training progress: 5500, Loss: 0.48710203170776367\n",
      "Training progress: 5600, Loss: 0.420888751745224\n",
      "Total loss: 845.5630493164062, Accuracy: 0.32690000534057617\n",
      "---------- Training round 9 finished ----------\n",
      "---------- Training round 10 started ----------\n",
      "Training progress: 5700, Loss: 0.34407779574394226\n",
      "Training progress: 5800, Loss: 0.5910012125968933\n",
      "Training progress: 5900, Loss: 0.454761266708374\n",
      "Training progress: 6000, Loss: 2.1233444213867188\n",
      "Training progress: 6100, Loss: 2.06377911567688\n",
      "Training progress: 6200, Loss: 0.5080494284629822\n",
      "Total loss: 553.927490234375, Accuracy: 0.5679000020027161\n",
      "---------- Training round 10 finished ----------\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "train1_model = MNISTModel().to(device)\n",
    "train1_loss_function = nn.CrossEntropyLoss().to(device)\n",
    "train1_learning_rate = 0.01\n",
    "train1_optimizer = optim.Adam(train1_model.parameters(), lr=train1_learning_rate)\n",
    "train1_accuracy = []\n",
    "\n",
    "# Training parameters\n",
    "total_epoch = 10\n",
    "current_progress = 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    print(\"---------- Training round {} started ----------\".format(epoch + 1))\n",
    "\n",
    "    # Train\n",
    "    train1_model.train()\n",
    "    for inputs, targets in train1_loader:\n",
    "        # Enable GPU\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Forward propagation\n",
    "        outputs = train1_model(inputs)\n",
    "        loss = train1_loss_function(outputs, targets)\n",
    "        # Backward propagation\n",
    "        train1_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train1_optimizer.step()\n",
    "        # Record progress\n",
    "        current_progress += 1\n",
    "        if current_progress % 100 == 0:\n",
    "            print(\"Training progress: {}, Loss: {}\".format(current_progress, loss.item()))\n",
    "\n",
    "    # Test\n",
    "    train1_model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            # Enable GPU\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            # Make perdiction\n",
    "            outputs = train1_model(inputs)\n",
    "            # Calculate loss\n",
    "            loss = train1_loss_function(outputs, targets)\n",
    "            total_loss += loss\n",
    "            # Calculate accuracy\n",
    "            correct = (outputs.argmax(1) == targets).sum()\n",
    "            total_correct += correct\n",
    "    # Record accuracy\n",
    "    accuracy = total_correct / test_size\n",
    "    train1_accuracy.append(accuracy.item())\n",
    "    print(\"Total loss: {}, Accuracy: {}\".format(total_loss, accuracy.item()))\n",
    "\n",
    "    print(\"---------- Training round {} finished ----------\".format(epoch + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e456c",
   "metadata": {},
   "source": [
    "### 在训练集 `train2.pt` 上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ef49f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Training round 1 started ----------\n",
      "Training progress: 100, Loss: 0.4447924494743347\n",
      "Training progress: 200, Loss: 0.39570069313049316\n",
      "Training progress: 300, Loss: 0.3407565951347351\n",
      "Training progress: 400, Loss: 0.399040162563324\n",
      "Training progress: 500, Loss: 0.42146843671798706\n",
      "Training progress: 600, Loss: 0.27119630575180054\n",
      "Total loss: 1136.679931640625, Accuracy: 0.12024999409914017\n",
      "---------- Training round 1 finished ----------\n",
      "---------- Training round 2 started ----------\n",
      "Training progress: 700, Loss: 0.2596578001976013\n",
      "Training progress: 800, Loss: 0.2789671719074249\n",
      "Training progress: 900, Loss: 0.1873481422662735\n",
      "Training progress: 1000, Loss: 0.15490418672561646\n",
      "Training progress: 1100, Loss: 0.4919430613517761\n",
      "Training progress: 1200, Loss: 0.32509228587150574\n",
      "Total loss: 1144.2132568359375, Accuracy: 0.11459999531507492\n",
      "---------- Training round 2 finished ----------\n",
      "---------- Training round 3 started ----------\n",
      "Training progress: 1300, Loss: 0.35926973819732666\n",
      "Training progress: 1400, Loss: 0.24082045257091522\n",
      "Training progress: 1500, Loss: 0.2162136733531952\n",
      "Training progress: 1600, Loss: 0.29192915558815\n",
      "Training progress: 1700, Loss: 0.22750411927700043\n",
      "Training progress: 1800, Loss: 0.23911991715431213\n",
      "Total loss: 1149.74072265625, Accuracy: 0.11140000075101852\n",
      "---------- Training round 3 finished ----------\n",
      "---------- Training round 4 started ----------\n",
      "Training progress: 1900, Loss: 0.2957727611064911\n",
      "Training progress: 2000, Loss: 0.4205789864063263\n",
      "Training progress: 2100, Loss: 0.34809502959251404\n",
      "Training progress: 2200, Loss: 0.44395947456359863\n",
      "Training progress: 2300, Loss: 0.24870936572551727\n",
      "Training progress: 2400, Loss: 0.4839978814125061\n",
      "Training progress: 2500, Loss: 0.27722224593162537\n",
      "Total loss: 1153.7320556640625, Accuracy: 0.10979999601840973\n",
      "---------- Training round 4 finished ----------\n",
      "---------- Training round 5 started ----------\n",
      "Training progress: 2600, Loss: 0.27284789085388184\n",
      "Training progress: 2700, Loss: 0.3811866044998169\n",
      "Training progress: 2800, Loss: 0.31501850485801697\n",
      "Training progress: 2900, Loss: 0.32540830969810486\n",
      "Training progress: 3000, Loss: 0.429735392332077\n",
      "Training progress: 3100, Loss: 0.2783687114715576\n",
      "Total loss: 1157.0052490234375, Accuracy: 0.10939999669790268\n",
      "---------- Training round 5 finished ----------\n",
      "---------- Training round 6 started ----------\n",
      "Training progress: 3200, Loss: 0.22180534899234772\n",
      "Training progress: 3300, Loss: 0.25763028860092163\n",
      "Training progress: 3400, Loss: 0.16776180267333984\n",
      "Training progress: 3500, Loss: 0.1368756890296936\n",
      "Training progress: 3600, Loss: 0.44521650671958923\n",
      "Training progress: 3700, Loss: 0.3460952937602997\n",
      "Total loss: 1158.8653564453125, Accuracy: 0.10884999483823776\n",
      "---------- Training round 6 finished ----------\n",
      "---------- Training round 7 started ----------\n",
      "Training progress: 3800, Loss: 0.3043283522129059\n",
      "Training progress: 3900, Loss: 0.2351616621017456\n",
      "Training progress: 4000, Loss: 0.22299635410308838\n",
      "Training progress: 4100, Loss: 0.2677191495895386\n",
      "Training progress: 4200, Loss: 0.22993069887161255\n",
      "Training progress: 4300, Loss: 0.22784024477005005\n",
      "Total loss: 1160.12646484375, Accuracy: 0.10819999873638153\n",
      "---------- Training round 7 finished ----------\n",
      "---------- Training round 8 started ----------\n",
      "Training progress: 4400, Loss: 0.2688087821006775\n",
      "Training progress: 4500, Loss: 0.3931261897087097\n",
      "Training progress: 4600, Loss: 0.3509696424007416\n",
      "Training progress: 4700, Loss: 0.39335981011390686\n",
      "Training progress: 4800, Loss: 0.24724863469600677\n",
      "Training progress: 4900, Loss: 0.49213024973869324\n",
      "Training progress: 5000, Loss: 0.2885926365852356\n",
      "Total loss: 1161.2103271484375, Accuracy: 0.10779999941587448\n",
      "---------- Training round 8 finished ----------\n",
      "---------- Training round 9 started ----------\n",
      "Training progress: 5100, Loss: 0.27025339007377625\n",
      "Training progress: 5200, Loss: 0.3691626787185669\n",
      "Training progress: 5300, Loss: 0.3054669201374054\n",
      "Training progress: 5400, Loss: 0.2854361832141876\n",
      "Training progress: 5500, Loss: 0.40945011377334595\n",
      "Training progress: 5600, Loss: 0.27985915541648865\n",
      "Total loss: 1162.2266845703125, Accuracy: 0.10764999687671661\n",
      "---------- Training round 9 finished ----------\n",
      "---------- Training round 10 started ----------\n",
      "Training progress: 5700, Loss: 0.2065657377243042\n",
      "Training progress: 5800, Loss: 0.2568894624710083\n",
      "Training progress: 5900, Loss: 0.1665886640548706\n",
      "Training progress: 6000, Loss: 0.12915462255477905\n",
      "Training progress: 6100, Loss: 0.4278280436992645\n",
      "Training progress: 6200, Loss: 0.3399478495121002\n",
      "Total loss: 1163.1168212890625, Accuracy: 0.10740000009536743\n",
      "---------- Training round 10 finished ----------\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "train2_model = MNISTModel().to(device)\n",
    "train2_loss_function = nn.CrossEntropyLoss().to(device)\n",
    "train2_learning_rate = 0.01\n",
    "train2_optimizer = optim.SGD(train2_model.parameters(), lr=train2_learning_rate)\n",
    "train2_accuracy = []\n",
    "\n",
    "# Training parameters\n",
    "total_epoch = 10\n",
    "current_progress = 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    print(\"---------- Training round {} started ----------\".format(epoch + 1))\n",
    "\n",
    "    # Train\n",
    "    train2_model.train()\n",
    "    for inputs, targets in train2_loader:\n",
    "        # Enable GPU\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Forward propagation\n",
    "        outputs = train2_model(inputs)\n",
    "        loss = train2_loss_function(outputs, targets)\n",
    "        # Backward propagation\n",
    "        train2_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train2_optimizer.step()\n",
    "        # Record progress\n",
    "        current_progress += 1\n",
    "        if current_progress % 100 == 0:\n",
    "            print(\"Training progress: {}, Loss: {}\".format(current_progress, loss.item()))\n",
    "\n",
    "    # Test\n",
    "    train2_model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            # Enable GPU\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            # Make perdiction\n",
    "            outputs = train2_model(inputs)\n",
    "            # Calculate loss\n",
    "            loss = train2_loss_function(outputs, targets)\n",
    "            total_loss += loss\n",
    "            # Calculate accuracy\n",
    "            correct = (outputs.argmax(1) == targets).sum()\n",
    "            total_correct += correct\n",
    "    # Record accuracy\n",
    "    accuracy = total_correct / test_size\n",
    "    train2_accuracy.append(accuracy.item())\n",
    "    print(\"Total loss: {}, Accuracy: {}\".format(total_loss, accuracy.item()))\n",
    "\n",
    "    print(\"---------- Training round {} finished ----------\".format(epoch + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89dc1f3",
   "metadata": {},
   "source": [
    "### 绘制学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d86fdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAE9CAYAAABtDit8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlc0lEQVR4nO3deZxU5Z3v8c+vm6VZRQFRaQTiwiqiNLjGuESDogMmMeKSZHLzimOiRiczzpg78SaTxFd0kjvjMDEh6Ki50YlRcY9bROMSrYZmkdCIIojSiNKg7HRDN7/7x1MNBfRSDXX6VJ36vl+vftWpU6dO/w7Kl+ec85znMXdHRERaVhJ3ASIi+U5BKSLSBgWliEgbFJQiIm1QUIqItEFBKSLShk5xF9Be/fr18yFDhsRdhogkzNy5c9e6e//mPiu4oBwyZAhVVVVxlyEiCWNm77f0mU69RUTaoKAUEWmDglJEpA0Fd42yOTt27KCmpoa6urq4S4lNWVkZ5eXldO7cOe5SRBInEUFZU1NDr169GDJkCGYWdzkdzt1Zt24dNTU1DB06NO5yRBInEafedXV19O3btyhDEsDM6Nu3b1G3qEWilIigBIo2JJsU+/GLRCkxQRmn9evX86tf/ard37vgggtYv359q9s89NBDjBo1ipKSEvUfFYmJgjIHWgrKxsbGVr/39NNP06dPn1a3GT16NI888ghnnHHGgZQoIgcgETdz4nbTTTexbNkyxo4dS+fOnenZsyeHH344CxYsYPHixUyZMoWVK1dSV1fH9ddfz1VXXQXsfspo8+bNnH/++Zx++um8/vrrDBw4kMcff5xu3boxYsSImI9OpLCsXw/33w9TpsDAgbnZp1qUOXDrrbdy1FFHsWDBAn7+858ze/ZsbrnlFhYvXgzA3Xffzdy5c6mqqmLatGmsW7dun30sXbqUa665hurqavr06cPMmTM7+jBEEuGNN+Daa+Gdd3K3z8S1KG+4ARYsyO0+x46F22/PfvsJEybs0U1n2rRpPProowCsXLmSpUuX0rdv3z2+M3ToUMaOHQvAuHHjWLFixYEVLVKkKiuhpAQqKnK3z8QFZT7o0aPHruU///nPvPDCC7zxxht0796dM888s9luPF27dt21XFpayrZt2zqkVpGkSaVg9Gjo1St3+0xcULan5ZcrvXr1YtOmTc1+tmHDBg4++GC6d+/OkiVLSKVSHVydSPHYuTO0KL/yldzuV9coc6Bv376cdtppjB49mhtvvHGPzyZOnEhDQwNjxozh5ptv5uSTT27Xvh999FHKy8t54403mDRpEl/4whdyWbpIorzzTriZ086/Zm2yQpvXu6KiwvfuT/jWW2/p7jD6cxC59174xjeguhpGjmzfd81srrs3e2VTLUoRSYzKSujdG4YPz+1+FZQikhipFJx0UrjrnUsKShFJhC1bYOHC3F+fBAWliCREVVW4662gFBFpQWVleJ0wIff7VlCKSCKkUnD00dCvX+73raDMgSiHWbvxxhsZPnw4Y8aM4eKLL25ze5Fi5B6e8Y7itBsUlDkR5TBr5557LosWLWLhwoUce+yx/OxnPzuQUkUSaeVK+OgjBWVeyxxmbfz48Zx11llcfvnlHHfccQBMmTKFcePGMWrUKGbMmLHre0OGDGHt2rWsWLGCESNG8K1vfYtRo0Zx3nnn7XrW+7zzzqNTp/Ck6cknn0xNTU3HH6BInmt6MjiqoMTdC+pn3LhxvrfFixfvs64jvffeez5q1Ch3d3/ppZe8e/fuvnz58l2fr1u3zt3dt27d6qNGjfK1a9e6u/vgwYO9trbW33vvPS8tLfX58+e7u/sll1ziv/vd7/b5PRdeeGGz65vE/ecgEpfvfc+9rMx9+/b93wdQ5S3kTuIGxbjh2RtY8NGCnO5z7GFjuX3i7VlvH8Uwa7fccgudOnXiiiuu2K9jEEmyVArGjYOoZmtOXFDmg1wPs/bb3/6Wp556ilmzZmkSMZG9bN8Oc+eGwXqjkrigbE/LL1eiHGbt2Wef5bbbbuPll1+me/fuuShXJFHefBPq6yO8PkkCgzIOmcOsdevWjQEDBuz6bOLEiUyfPp0xY8YwbNiwdg+zdu2111JfX8+5554LhBs606dPz2n9IoWsqe1x0knR/Q4Ns5Yg+nOQYnTllfDSS1BTAwdyZUrDrIlIYqVS4bQ7ysv3CkoRKVi1tbBsWbTXJ0FBKSIFrGkgDAVllgrtWmuuFfvxS3FKpaC0NPShjFIigrKsrIx169YVbVi4O+vWraOsrCzuUkQ6VGUljBkDUfecS0T3oPLycmpqaqitrY27lNiUlZVRXl4edxkiHaaxMQTllVdG/7sSEZSdO3fe45FBEUm+JUtg06bor09CQk69RaT4RD5iUAYFpYgUpMpKOPhgOOaY6H+XglJEClLT1LQdMU6MglJECs6mTbBoUcecdoOCUkQK0Jw5YZ6cRASlmU00s7fN7F0zu6mZz880sw1mtiD983+irEdEkqHpRk4UU9M2J7LuQWZWCtwBnAvUAHPM7Al3X7zXpq+6+4VR1SEiyVNZCcOGhZs5HSHKFuUE4F13X+7u24EHgMkR/j4RKQLuu0cM6ihRBuVAYGXG+5r0ur2dYmZvmtkzZjYqwnpEJAFWrIA1azo2KKN8Mqe5m/Z7P4w9Dxjs7pvN7ALgMWCfXlFmdhVwFcCRRx6Z4zJFpJB0ZEfzJlG2KGuAQRnvy4EPMzdw943uvjm9/DTQ2cz67b0jd5/h7hXuXtG/f/8ISxaRfJdKhUEwRo/uuN8ZZVDOAY4xs6Fm1gWYCjyRuYGZHWbpaQXNbEK6nnUR1iQiBa6yEioqoFMHjlQRWVC6ewNwLfAc8BbwoLtXm9nVZnZ1erMvA4vM7E1gGjDVi3WsNBFpU309zJ/fsafdEPHoQenT6af3Wjc9Y/mXwC+jrEFEkmP+/DCPd0cHpZ7MEZGC0RFT0zZHQSkiBaOyEgYNgiOO6Njfq6AUkYLR0R3NmygoRaQgfPRR6GyuoBQRaUFHTU3bHAWliBSEVAo6d4YTTuj4362gFJGCUFkJxx8P3bp1/O9WUIpI3mtshNmz4zntBgWliBSA6mrYskVBKSLSojhGDMqkoBSRvJdKQb9+8JnPxPP7FZQikvcqKztuatrmKChFJK+tXw+LF8d32g0KShHJc3PmhFcFpYhIC1KpcMo9fnx8NSgoRSSvpVIwYgQcdFB8NSgoRSRvuYcbOXGedoOCUkTy2LJlsG6dglJEpEVxdzRvoqAUkbyVSkHPnjByZLx1KChFJG9VVoa73aWl8dahoBSRvLRtGyxYEP9pNygoRSRPzZsHDQ0KShGRFsU1NW1zFJQikpdSKRgyBAYMiLsSBaWI5Kl86GjeREEpInln1SpYuVJBKSLSojinpm2OglJE8k4qBV26wNixcVcSKChFJO+kUmH+7q5d464kUFCKSF5paICqqvw57QYFpYjkmb/+NTyVo6AUEWlBvowYlElBKSJ5JZUKncwHD467kt0UlCKSV1KpeKembY6CUkTyxiefwDvv5NdpNygoRSSPzJ4dXhWUIiItSKWgpAQqKuKuZE8KShHJG6kUjBoFvXrFXcmeFJQikhd27gyn3vl22g0KShHJE0uXwqefKihFRFqUjx3NmygoRSQvpFLQuzcMHx53JftSUIpIXkilYMKEcNc73+RhSSJSbLZsCYNh5ONpN0QclGY20czeNrN3zeymVrYbb2aNZvblKOsRkfw0dy40NhZhUJpZKXAHcD4wErjMzEa2sN1twHNR1SIi+S2fpqZtTpQtygnAu+6+3N23Aw8Ak5vZ7jpgJrAmwlpEJI+lUnD00dCvX9yVNC/KoBwIrMx4X5Net4uZDQQuBqa3tiMzu8rMqsysqra2NueFikh83HePGJSvogzK5gZJ8r3e3w78s7s3trYjd5/h7hXuXtG/f/9c1ScieaCmBlavzt/rkwCdItx3DTAo43058OFe21QAD1gYeK4fcIGZNbj7YxHWJSJ5JJ87mjeJMijnAMeY2VBgFTAVuDxzA3cf2rRsZvcCTykkRYpLKgVlZTBmTNyVtCyyoHT3BjO7lnA3uxS4292rzezq9OetXpcUkeKQSsG4cWEe73wVZYsSd38aeHqvdc0GpLv/bZS1iEj+2b499KG85pq4K2mdnswRkdgsXAj19fl9fRIUlCISo0K4kQMKShGJUSoFRxwB5eVxV9I6BaWIxCYfp6ZtjoJSRGKxdi0sW5b/p92goBSRmFRWhlcFpYhIC1IpKC0NfSjzXZtBaWYXmpkCVURyKpUKT+P06BF3JW3LJgCnAkvN7N/MbETUBYlI8jVNTZvPIwZlajMo3f1K4ARgGXCPmb2RHvYsz6YoF5FCsWQJbNxYGNcnIctrlO6+kTC47gPA4YQxJOeZ2XUR1iYiCVUoHc2bZHON8iIzexR4EegMTHD384HjgX+MuD4RSaBUCg4+GI45Ju5KspPNoBiXAP/h7q9krnT3rWb2v6IpS0SSrKmjeT5OTducbMr8ITC76Y2ZdTOzIQDuPiuiukQkoTZtgkWLCudGDmQXlA8BOzPeN6bXiYi0W1VVmCenUK5PQnZB2Sk9iyIA6eU8HmJTRPJZ042cCRPiraM9sgnKWjP7m6Y3ZjYZWBtdSSKSZKkUDBsGhxwSdyXZy+ZmztXA/Wb2S8LMiiuBr0ValYgkUtPUtBMnxl1J+7QZlO6+DDjZzHoC5u6boi9LRJJoxQpYs6awrk9ClnPmmNkkYBRQlp5aFnf/cYR1iUgCFdKIQZmy6XA+HbgUuI5w6n0JMDjiukQkgVIp6NYNjjsu7kraJ5ubOae6+9eAT939X4FTgEHRliUiSZRKwfjx0CnS+V9zL5ugrEu/bjWzI4AdwNDoShKRJKqvh/nzC6ujeZNscv1JM+sD/ByYBzhwZ5RFiUjyLFgQ5vEutOuT0EZQpgfsneXu64GZZvYUUObuGzqiOBFJjkIbMShTq6fe7r4T+L8Z7+sVkiKyP1IpGDQoTE9baLK5Rvm8mX3JLN8nlBSRfJZKFWZrErILyu8RBsGoN7ONZrbJzDZGXJeIJMjHH4fO5oV4IweyezJHUz6IyAEp1I7mTdoMSjM7o7n1ew/kKyLSklQq9J088cS4K9k/2XQPujFjuQyYAMwFzo6kIhFJnFQKxo4NT+UUomxOvS/KfG9mg4B/i6wiEUmUxsYwNe03vhF3Jftvf2asqAFG57oQEUmm6mrYsqVwb+RAdtco/4vwNA6EYB0LvBlhTSKSEPX1cOutYfmUU+Kt5UBkc42yKmO5Afi9u/8lonpEJCE+/hi++EV4/XX48Y/hqKPirmj/ZROUDwN17t4IYGalZtbd3bdGW5qIFKr582HyZFi7Fh58EC65JO6KDkw21yhnAZn3qroBL0RTjogUupkz4fTTw7QPr71W+CEJ2QVlmbtvbnqTXu4eXUkiUoh27oR//Vf48pfh+ONhzpzC7Te5t2yCcouZ7TpcMxsHbIuuJBEpNFu2wKWXwo9+BF//Orz0Ehx2WNxV5U421yhvAB4ysw/T7w8nTA0hIsIHH4TrkQsXwi9+Ad/7HiRtCJ1sOpzPMbPhwDDCnDlL3H1H5JWJSN57/XW4+GKoq4OnnoLzz4+7omhkM7nYNUAPd1/k7n8FeprZd6IvTUTy2b33wllnQe/e4RHFpIYkZHeN8lvpEc4BcPdPgW9FVpGI5LXGRviHfwiPJJ5xRhgZaMSIuKuKVjbXKEvMzNzdIfSjBLpEW5aI5KMNG2DqVHj2WbjuOvj3fy+8GRX3RzYtyueAB83sHDM7G/g98Ew2OzeziWb2tpm9a2Y3NfP5ZDNbaGYLzKzKzE5vX/ki0lGWLg3Pa7/wAsyYAdOmFUdIQnYtyn8GrgK+TbiZM59w57tV6ZbnHcC5hIE05pjZE+6+OGOzWcAT7u5mNgZ4EBjevkMQkaj96U/wla+EYJw1K5xyF5M2W5TpCcZSwHKgAjgHeCuLfU8A3nX35e6+HXgAmLzXvjc3ndIDPdg9+IaI5AH30HI8//wwMdjs2cUXktBKi9LMjgWmApcB64A/ALj7WVnueyCwMuN9DbDPQEtmdjHwM+BQYFKW+xaRiG3fDtdcA3fdFfpJ/u530KtIJ4ZprUW5hNB6vMjdT3f3/wIa27Hv5rqc7tNidPdH3X04MAX4SbM7MrsqfQ2zqra2th0liMj+qK2Fz38+hOS//As88kjxhiS0HpRfAj4CXjKzO83sHJoPv5bUAIMy3pcDH7awbdMcPEeZWb9mPpvh7hXuXtG/f/92lCAi7bVwIYwfH57V/p//gZ/+FEr2Z4jvBGnx8NMtvUsJN1f+DPw9MMDMfm1m52Wx7znAMWY21My6EE7jn8jcwMyObpovPP08eRfCab6IxOCxx+DUU2HHDnjlFbjssrgryg/Z3MzZ4u73u/uFhFbhAmCfrj7NfK8BuJbQvegt4EF3rzazq83s6vRmXwIWmdkCwh3ySzNu7ohIB3EPLceLL4ZRo0Jrcvz4uKvKH1ZouVRRUeFVVVVtbygiWdm6Fb75TXjgAbjiCrjzzsKdLfFAmNlcd69o7rMi6S4qIs2pqYEpU2DevDC3zT/9U/JG/skFBaVIkaqsDCG5eTM8/jhcdFGbXylaRX4vS6Q43XcffO5z0L17GPlHIdk6BaVIkfnxj+GrXw3Tx86eHW7eSOsUlCJF5JZb4Ic/DNM1PP889O0bd0WFQdcoRYrEL34BP/hBaE3+939DaWncFRUOtShFisC0aXDjjWEEoLvvVki2l4JSJOF+8xu4/vrQmfy++4pnDMlcUlCKJNg998DVV8OkSaFDeefOcVdUmBSUIgl1333hiZvzzoOHH4YumsBlvykoRRLowQfDne0zzwwDXZSVxV1RYVNQiiTMY4/B5ZeHUYCefLI4n9vONQWlSIL88Y/hzvb48fD009CjR9wVJYOCUiQhnn8evvQlGDMGnnmmuEckzzUFpUgCvPRSmNdm+PAQmH36xF1RsigoRQrca6/BhRfCUUeFaWUPOSTuipJHQSlSwCor4YILwlSyL7wAmlIqGgpKkQI1dy584Qtw6KEwaxYcdljcFSWXglKkAL35ZuhIfvDB8OKLMHBg3BUlm4JSpMBUV4c5t7t3DyF55JFxV5R8CkqRAvL223DOOeGZ7RdfhKFD466oOCgoRQrEsmVw9tlhatlZs+CYY+KuqHhowCWRArBiRQjJ+nr4859hxIi4KyouCkqRPLdyZQjJjRvD6fbo0XFXVHwUlCJ5bPXqcE1y3brQT/KEE+KuqDgpKEXy1Jo1ISRXr4bnngsDXUg8FJQieWjdutAF6P33wwAXp54ad0XFTUEpkmc+/RTOPReWLoWnnoIzzoi7IlFQiuSRDRvCY4nV1fD44+HUW+KnoBTJE5s2hQEu5s+HRx6BiRPjrkiaKChF8sDWrXDRRWE0oD/8ISxL/lBQisRs27Yw6O6rr8L994dRyiW/6BFGkRht3gxTpoRHEu+5B6ZOjbsiaY5alCIxWbMGJk0K1yTvvhu+9rW4K5KWKChFYrB8ebi7vWpVmF72wgvjrkhao6AU6WDz58P558P27eGU+5RT4q5I2qJrlCId6MUX4XOfgy5d4C9/UUgWCgWlSAf5wx9C38gjj4TXX9dQaYVEQSnSAaZNg8sug5NOCt2AysvjrkjaQ0EpEiF3+P734frrQ1/J558PE4JJYdHNHJGI7NgBV10F994Lf/d3cMcdUFoad1WyP9SiFInAli2hI/m998KPfgS//rVCspCpRSmSY2vXhn6Rc+bA9OmhNSmFTUEpkkPvvx86kq9YATNnhlalFD4FpUiOLFwYuv9s2xbmtzn99LgrklyJ9BqlmU00s7fN7F0zu6mZz68ws4Xpn9fN7Pgo6xGJyssvh5HIS0pC9x+FZLJEFpRmVgrcAZwPjAQuM7ORe232HvA5dx8D/ASYEVU9IlGZOTOcbh9xROhIrulkkyfKFuUE4F13X+7u24EHgMmZG7j76+7+afptClA3XCkov/41XHIJnHgivPZaeOpGkifKoBwIrMx4X5Ne15JvAs9EWI9IzrjDzTfDd74T7nC/8AIcckjcVUlUoryZY82s82Y3NDuLEJTNXtkxs6uAqwCO1D/ZErOGBvj2t+Guu+Cb3wxdgDrptmiiRdmirAEGZbwvBz7ceyMzGwPcBUx293XN7cjdZ7h7hbtX9O/fP5JiRbKxdWuYquGuu+AHP4A771RIFoMo/xPPAY4xs6HAKmAqcHnmBmZ2JPAI8FV3fyfCWhLrrbfC/M/jx8Phh8ddTbJ98kmY9OuNN8LjiN/5TtwVSUeJLCjdvcHMrgWeA0qBu9292syuTn8+Hfg/QF/gV2YG0ODuFVHVlBTLl4chux54IPTda3LUUfDZz4auKaefDsceC9bcBZACsmNHON7DDoODDoqvjpUrw53tZcvgoYc0AVixMfdmLxvmrYqKCq+qqoq7jA63ahU8+GAIx9mzw7pTT4VLLw13XGfPDv33XnstPEIH0L9/CMym8DzhhPw+Tdy2LQT/vHlhFPB58+Cvfw0jgUMYmmzkSBg1KvyMHBl+og7Q6uoQkps2wRNPhIF3JXnMbG5LDTUFZR6rrYWHHw7h+Oqr4U7riSeGmfq+8hUYPHjf77jD22+HwGwKzuXLw2c9esDJJ+8Oz5NOgp49O/aYmmzcCAsWhDBs+lmyBBobw+cHHxyO9cQTQxh+9FEIrOrqcLmhrm73vqIM0NdeC6fb3brBs8/CmDEHvk/JTwrKArJ+PTz6aAjHWbNCcIwYEQZ9vfTScDrdXh9+GP7CN4Xnm2+GQC0tDUHUdKp++ulw6KE5PyRqa3e3EJte33139+eHHx7qOOGE3eF45JEtXzZobAzPUldXw+LF0QXoY4+FP/fBg+G555r/h0mSQ0GZ5zZvhiefDOH47LPhVPMznwnBOHUqHHdcbq81btgQbkg0BWdlJdTXh8+OPXbP65xHHZX973YPlwiawrApGFdm9KYdMmR3GJ5wQvjJ1U2opgDNDM/Fi0OAbtu2e7tsAnTGjNAFaPx4eOop6NcvNzVK/lJQ5qG6OnjmmRCOTz4Z/iIPHLg7HCsqOu5GTH09zJ27Ozj/8hf4NP281GGH7Xmd8/jjQ0vUPZzSZ7YS580LrUcItQ8btmdLcezYeDplZxugAweG4OzTJ1wPvuCC8NqjR8fXLB1PQZknduwIT3A88EA4vd60KdxwueSSEI6nnRYGVYjbzp0hRJqucb76KnzwQfisVy8YPhzeeSe0TCHcIBo1andL8cQTw7W8uK5/ZquxMQyLlhme1dWhu9XUqaELUOfOcVcpHUVBGaPGRnjllRCODz8c+uIddFDoXjJ1Kpx1Vn7fiW7ywQe7r3MuWRLCsqmlOHo0dO0ad4UiB6a1oCyAv6KFZ+dOSKVCOD70ULhj26NHmFzq0ktDV5NCC5Yjj4TLLw8/IsVGQZlD27fDf/wH/OpXoQXWtStMmhRajpMmQffucVcoIvtDQZkjL70UHmlbsgQ+/3n46U9DC7J377grE5EDpaA8QB99BP/4j3D//TB0aOhKMmlS3FWJSC7lwT3WwtTYGO6KDh8eupD84AewaJFCUiSJ1KLcD1VVcPXVoe/hOeeEwBw2LO6qRCQqalG2w/r1cM01MGFCeALl97+HP/1JISmSdArKLLjDffeFQJw+Ha67Lty0mTq18IcxE5G26dS7DYsXh7vZL78cWpLPPBM6WYtI8VCLsgVbt8L3vx+ebV64EH7zmzCQhEJSpPioRdmMJ56A7343PAf8t38Lt90WzfBjIlIY1KLMsGJF6CQ+eXIY0OGVV+CeexSSIsVOQUl49PDWW8OYhLNmwc9/HoYO++xn465MRPJB0Z96Zz56+MUvwu23w6BBbX5NRIpI0bYoP/4YvvpVOPvsMHDtH/8IM2cqJEVkX0UXlI2NYXSfYcPCo4c33xwGa73ggrgrE5F8VVSn3lVVYR6Uqio9eigi2SuKFmXmo4c1NXr0UETaJ9FBqUcPRSQXEn3qvWMH/OQnYYpUPXooIvsr0UHZpUvoF3nEEfkxu6GIFKZEByWEye5FRA6E2lkiIm1QUIqItEFBKSLSBgWliEgbFJQiIm1QUIqItEFBKSLSBgWliEgbEh+U81fP591P3mXbjm1xlyIiBSrxT+Z88cEvsmL9CgAO6XYIA3sNpLx3OeW9y3ctD+w9cNf7PmV9MI2YISIZEh+U90y+h/fXv8+qTauo2Viz63Xe6nl8vOXjfbbv3rn7niG6V5iW9y7n0B6HUmKJb4yLSFrig/LMIWe2+Nn2xu2s3rR6jwDNXH7l/VdYtWkVDTsb9vhep5JOHNHriBbDdECPAfQp68NBZQfRpbRLxEcoIlFLfFC2pktpFwb3GczgPoNb3Gan76R2S+0eAbpq4ypqNoXXhR8v5OmlT7Nlx5Zmv9+tU7ddodmnrA8HdQ2vmcvNfpZe16NzD10KEIlZUQdlNkqshAE9BzCg5wDGMa7ZbdydjfUbdwXpmi1r2FC3gfV169lQv+frp3WfsmL9il3r6hrqWv39pVa6T5A2ve/TNSz37tqbsk5llHUqo2tp113Lu9Z12nNd5jadSjopiEXaoKDMATPjoLKDOKjsIEb2H9mu79Y11LGhbsPuQE0H7B4hW7eB9fXrdy0v+2TZrs821m88oNpLrKTZgN07XDO36VraldKSUgyjxEpy+mPW/D5LrTS8lpRmvVxaUrrru60tt7aPTiWd9thfqZXqH5YipKCMWVmnMsp6ljGg54D9+n7jzka27NhCXUMd9Q311DXU7fFT39jMumy3S6/7ZNsn+3x3p+/c9eP4Hu+b+0kSw5oN0NKSdLDuta6tzzqVdMr5PzglVtLqP2RmhmG7XoE91jUdZy4/b+735nJd0zE3rTtl0Ckc2uPQnPw3V1AWuNKSUnp37U3vrr3jLqVV7m2HaUvh27izMbx6Y6vLjd64a/vWltuzv4adDXt8L5vPGnY2hOWW1u/1nR07d+w+7nb+ObXnz3Gfz9xxfNd/n6blpHj+yuc596hzc7KvSIPSzCYC/wmUAne5+617fT4cuAc4EfgXd/9FlPVIfMwstKIojbsUyUJTcLqngzS9vHewtvfzpvDO/Hx/12WGfXPrjj7k6Jz9eUQWlGZWCtwBnAvUAHPM7Al3X5yx2SfAd4EpUdUhIu2365RZl2OBaB9hnAC86+7L3X078AAwOXMDd1/j7nOAHRHWISJyQKIMyoHAyoz3Nel17WZmV5lZlZlV1dbW5qQ4EZFsRRmUzTXa9+tqsbvPcPcKd6/o37//AZYlItI+UQZlDTAo43058GGEv09EJBJRBuUc4BgzG2pmXYCpwBMR/j4RkUhEdtfb3RvM7FrgOUL3oLvdvdrMrk5/Pt3MDgOqgN7ATjO7ARjp7gf2uImISA5F2o/S3Z8Gnt5r3fSM5Y8Ip+QiInlLgyqKiLRBQSki0gYFpYhIG6zpWcxCYWa1wPtx19GGfsDauIuIUNKPD5J/jEk/Pmj/MQ5292Y7ahdcUBYCM6ty94q464hK0o8Pkn+MST8+yO0x6tRbRKQNCkoRkTYoKKMxI+4CIpb044PkH2PSjw9yeIy6Riki0ga1KEVE2qCgzCEzG2RmL5nZW2ZWbWbXx11TFMys1Mzmm9lTcdeSa2bWx8weNrMl6f+Op8RdU66Z2d+n//9cZGa/N7OyuGs6EGZ2t5mtMbNFGesOMbM/mdnS9OvBB/I7FJS51QD8g7uPAE4GrjGz9s1fWxiuB96Ku4iI/CfwrLsPB44nYcdpZgMJ069UuPtowoA1U+Ot6oDdC0zca91NwCx3PwaYlX6/3xSUOeTuq919Xnp5E+Ev2X6N6p6vzKwcmATcFXctuWZmvYEzgP8GcPft7r4+1qKi0QnoZmadgO4U+Dix7v4KYf6tTJOB36aXf8sBzsuloIyImQ0BTgAqYy4l124H/glI1mTdwWeAWuCe9KWFu8ysR9xF5ZK7rwJ+AXwArAY2uPvz8VYViQHuvhpCAwY4oAm+FZQRMLOewEzghiSNrWlmFwJr3H1u3LVEpBNh6uRfu/sJwBYO8JQt36Sv1U0GhgJHAD3M7Mp4q8p/CsocM7POhJC8390fibueHDsN+BszW0GYVfNsM7sv3pJyqgaocfems4CHCcGZJJ8H3nP3WnffATwCnBpzTVH42MwOB0i/rjmQnSkoc8jMjHB96y13//e468k1d/++u5e7+xDCDYAX3T0xrZH0QNIrzWxYetU5wOJWvlKIPgBONrPu6f9fzyFhN6zSngC+nl7+OvD4gews0hHOi9BpwFeBv5rZgvS6/50e6V0Kw3XA/el5npYD34i5npxy90ozexiYR+ilMZ8Cf0rHzH4PnAn0M7Ma4IfArcCDZvZNwj8OlxzQ79CTOSIirdOpt4hIGxSUIiJtUFCKiLRBQSki0gYFpYhIGxSUUhDMrNHMFmT85OyJGTMbkjnyjMje1I9SCsU2dx8bdxFSnNSilIJmZivM7DYzm53+OTq9frCZzTKzhenXI9PrB5jZo2b2Zvqn6fG9UjO7Mz1O4/Nm1i22g5K8o6CUQtFtr1PvSzM+2+juE4BfEkY3Ir38/9x9DHA/MC29fhrwsrsfT3iOuzq9/hjgDncfBawHvhTp0UhB0ZM5UhDMbLO792xm/QrgbHdfnh6Q5CN372tma4HD3X1Hev1qd+9nZrVAubvXZ+xjCPCn9CCvmNk/A53d/acdcGhSANSilCTwFpZb2qY59RnLjej6vWRQUEoSXJrx+kZ6+XV2T3FwBfBaenkW8G3YNfdP744qUgqX/tWUQtEtY0QmCPPaNHUR6mpmlYR/+C9Lr/sucLeZ3UgYtbxpFKDrgRnpUWUaCaG5OuripbDpGqUUtPQ1ygp3Xxt3LZJcOvUWEWmDWpQiIm1Qi1JEpA0KShGRNigoRUTaoKAUEWmDglJEpA0KShGRNvx//ytsLqZ+foYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate data points\n",
    "x = np.linspace(1, 10, 10, dtype=np.int_)\n",
    "y1 = np.array(train1_accuracy)\n",
    "y2 = np.array(train2_accuracy)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, y1, c='b', label='train1')\n",
    "plt.plot(x, y2, c='g', label='train2')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
